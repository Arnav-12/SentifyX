{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From d:\\WorkSpace\\Projects\\Sentify\\venv\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "config.json: 100%|██████████| 759/759 [00:00<00:00, 762kB/s]\n",
      "d:\\WorkSpace\\Projects\\Sentify\\venv\\lib\\site-packages\\huggingface_hub\\file_download.py:147: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Acer\\.cache\\huggingface\\hub. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "model.safetensors: 100%|██████████| 541M/541M [00:06<00:00, 80.2MB/s] \n",
      "tokenizer_config.json: 100%|██████████| 373/373 [00:00<00:00, 373kB/s]\n",
      "vocab.txt: 100%|██████████| 996k/996k [00:00<00:00, 1.17MB/s]\n",
      "tokenizer.json: 100%|██████████| 2.92M/2.92M [00:00<00:00, 26.5MB/s]\n",
      "special_tokens_map.json: 100%|██████████| 125/125 [00:00<00:00, 112kB/s]\n",
      "d:\\WorkSpace\\Projects\\Sentify\\venv\\lib\\site-packages\\transformers\\pipelines\\text_classification.py:105: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline \n",
    "\n",
    "sentiment_classifier = pipeline(\n",
    "            model=\"lxyuan/distilbert-base-multil    ingual-cased-sentiments-student\",\n",
    "            return_all_scores=True\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'label': 'positive', 'score': 0.6705206632614136},\n",
       "  {'label': 'neutral', 'score': 0.14323367178440094},\n",
       "  {'label': 'negative', 'score': 0.18624572455883026}]]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_classifier([\"Hello this is yo yo honey singh\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/20/2023 12:36:42 - INFO - huggingsound.speech_recognition.model - Loading model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "config.json: 100%|██████████| 1.53k/1.53k [00:00<?, ?B/s]\n",
      "d:\\WorkSpace\\Projects\\Sentify\\venv\\lib\\site-packages\\huggingface_hub\\file_download.py:147: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Acer\\.cache\\huggingface\\hub. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "model.safetensors: 100%|██████████| 1.26G/1.26G [00:17<00:00, 71.1MB/s]\n",
      "preprocessor_config.json: 100%|██████████| 262/262 [00:00<?, ?B/s] \n",
      "vocab.json: 100%|██████████| 300/300 [00:00<00:00, 303kB/s]\n",
      "special_tokens_map.json: 100%|██████████| 85.0/85.0 [00:00<?, ?B/s]\n",
      "100%|██████████| 1/1 [00:08<00:00,  8.17s/it]\n"
     ]
    }
   ],
   "source": [
    "from huggingsound import SpeechRecognitionModel\n",
    "\n",
    "model = SpeechRecognitionModel(\"jonatasgrosman/wav2vec2-large-xlsr-53-english\")\n",
    "audio_paths = ['artifacts\\Audio\\main.wav']\n",
    "\n",
    "transcriptions = model.transcribe(audio_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'my name is bogalas iam ajournalist from norway living in bellin iam very interested in the huge changes that are happening in the field of work in europe in the wake of enormous technological changes as well as political handling of globalization'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transcriptions[0]['transcription']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "config.json: 100%|██████████| 1.92k/1.92k [00:00<?, ?B/s]\n",
      "model.safetensors: 100%|██████████| 499M/499M [00:25<00:00, 19.9MB/s] \n",
      "tokenizer_config.json: 100%|██████████| 380/380 [00:00<00:00, 380kB/s]\n",
      "vocab.json: 100%|██████████| 798k/798k [00:00<00:00, 2.79MB/s]\n",
      "merges.txt: 100%|██████████| 456k/456k [00:00<00:00, 731kB/s]\n",
      "tokenizer.json: 100%|██████████| 2.11M/2.11M [00:00<00:00, 4.95MB/s]\n",
      "special_tokens_map.json: 100%|██████████| 280/280 [00:00<?, ?B/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': 'disappointment', 'score': 0.4666951298713684}, {'label': 'sadness', 'score': 0.398495078086853}, {'label': 'annoyance', 'score': 0.06806593388319016}, {'label': 'neutral', 'score': 0.05703022703528404}, {'label': 'disapproval', 'score': 0.044239308685064316}, {'label': 'nervousness', 'score': 0.014850731007754803}, {'label': 'realization', 'score': 0.014059904962778091}, {'label': 'approval', 'score': 0.0112674655392766}, {'label': 'joy', 'score': 0.0063033876940608025}, {'label': 'remorse', 'score': 0.006221496034413576}, {'label': 'caring', 'score': 0.006029403302818537}, {'label': 'embarrassment', 'score': 0.005265488289296627}, {'label': 'anger', 'score': 0.0049814279191195965}, {'label': 'disgust', 'score': 0.004259031731635332}, {'label': 'grief', 'score': 0.004002134781330824}, {'label': 'confusion', 'score': 0.003382916795089841}, {'label': 'relief', 'score': 0.003140497487038374}, {'label': 'desire', 'score': 0.0028274671640247107}, {'label': 'admiration', 'score': 0.002815793501213193}, {'label': 'fear', 'score': 0.002707524225115776}, {'label': 'optimism', 'score': 0.002616488840430975}, {'label': 'love', 'score': 0.002488391939550638}, {'label': 'excitement', 'score': 0.0024494766257703304}, {'label': 'curiosity', 'score': 0.0023743617348372936}, {'label': 'amusement', 'score': 0.0017466946737840772}, {'label': 'surprise', 'score': 0.0014529851032420993}, {'label': 'gratitude', 'score': 0.0006464761681854725}, {'label': 'pride', 'score': 0.0005542495055124164}]\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "classifier = pipeline(task=\"text-classification\", model=\"SamLowe/roberta-base-go_emotions\", top_k=None)\n",
    "\n",
    "sentences = [\"I am not having a great day\"]\n",
    "\n",
    "model_outputs = classifier(sentences)\n",
    "print(model_outputs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'admiration', 'score': 0.8186381459236145},\n",
       " {'label': 'approval', 'score': 0.08546392619609833},\n",
       " {'label': 'neutral', 'score': 0.05038803070783615},\n",
       " {'label': 'love', 'score': 0.037321172654628754},\n",
       " {'label': 'joy', 'score': 0.0334685742855072},\n",
       " {'label': 'caring', 'score': 0.03331969678401947},\n",
       " {'label': 'gratitude', 'score': 0.019389722496271133},\n",
       " {'label': 'optimism', 'score': 0.007429832126945257},\n",
       " {'label': 'pride', 'score': 0.0057520573027431965},\n",
       " {'label': 'realization', 'score': 0.0046065449714660645},\n",
       " {'label': 'disapproval', 'score': 0.003838461358100176},\n",
       " {'label': 'excitement', 'score': 0.0037130604032427073},\n",
       " {'label': 'relief', 'score': 0.0030083046294748783},\n",
       " {'label': 'annoyance', 'score': 0.0027571357786655426},\n",
       " {'label': 'sadness', 'score': 0.002226512646302581},\n",
       " {'label': 'desire', 'score': 0.0019701977726072073},\n",
       " {'label': 'disappointment', 'score': 0.0014966872986406088},\n",
       " {'label': 'amusement', 'score': 0.0012969966046512127},\n",
       " {'label': 'anger', 'score': 0.0011359151685610414},\n",
       " {'label': 'confusion', 'score': 0.0007875064620748162},\n",
       " {'label': 'curiosity', 'score': 0.0007227788446471095},\n",
       " {'label': 'remorse', 'score': 0.0007206137524917722},\n",
       " {'label': 'grief', 'score': 0.0006759159732609987},\n",
       " {'label': 'disgust', 'score': 0.0005522706778720021},\n",
       " {'label': 'fear', 'score': 0.00045006192522123456},\n",
       " {'label': 'surprise', 'score': 0.0004094859177712351},\n",
       " {'label': 'embarrassment', 'score': 0.00028365664184093475},\n",
       " {'label': 'nervousness', 'score': 0.00027172552654519677}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier([\"He was nice to me\"])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'d:\\\\WorkSpace\\\\Projects\\\\Sentify\\\\Can you name these times of day learnenglish english vocabulary.3gpp'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pytube import YouTube\n",
    "\n",
    "YouTube(\"https://www.youtube.com/shorts/Gno-zBED01Y\").streams.first().download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Writing audio in audio.mp3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "import moviepy.editor as mp\n",
    "\n",
    "clip = mp.VideoFileClip('./Can you name these times of day learnenglish english vocabulary.3gpp')\n",
    "clip.audio.write_audiofile(\"audio.mp3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:05<00:00,  5.21s/it]\n"
     ]
    }
   ],
   "source": [
    "text = model.transcribe(['./audio.mp3'])[0]['transcription']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:05<00:00,  5.36s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'transcription': 'can you name these times of day dawnmorningnoonafternoondusk evening and night',\n",
       "  'start_timestamps': [140,\n",
       "   220,\n",
       "   260,\n",
       "   300,\n",
       "   340,\n",
       "   380,\n",
       "   400,\n",
       "   440,\n",
       "   500,\n",
       "   600,\n",
       "   680,\n",
       "   700,\n",
       "   740,\n",
       "   960,\n",
       "   1000,\n",
       "   1140,\n",
       "   1280,\n",
       "   1340,\n",
       "   1400,\n",
       "   1740,\n",
       "   1900,\n",
       "   1940,\n",
       "   1980,\n",
       "   2020,\n",
       "   2060,\n",
       "   2100,\n",
       "   2120,\n",
       "   2140,\n",
       "   2200,\n",
       "   2340,\n",
       "   2400,\n",
       "   2480,\n",
       "   3340,\n",
       "   3580,\n",
       "   3640,\n",
       "   3720,\n",
       "   5560,\n",
       "   5680,\n",
       "   5720,\n",
       "   5800,\n",
       "   5920,\n",
       "   5980,\n",
       "   6020,\n",
       "   8360,\n",
       "   8440,\n",
       "   8560,\n",
       "   8640,\n",
       "   10600,\n",
       "   10700,\n",
       "   10800,\n",
       "   10860,\n",
       "   10900,\n",
       "   10960,\n",
       "   11000,\n",
       "   11120,\n",
       "   11140,\n",
       "   12600,\n",
       "   12800,\n",
       "   12960,\n",
       "   13140,\n",
       "   13260,\n",
       "   15480,\n",
       "   15580,\n",
       "   15640,\n",
       "   15720,\n",
       "   15820,\n",
       "   15880,\n",
       "   15920,\n",
       "   16020,\n",
       "   17480,\n",
       "   17560,\n",
       "   17640,\n",
       "   17720,\n",
       "   18440,\n",
       "   18540,\n",
       "   18580,\n",
       "   18620,\n",
       "   18680],\n",
       "  'end_timestamps': [160,\n",
       "   240,\n",
       "   280,\n",
       "   320,\n",
       "   360,\n",
       "   400,\n",
       "   420,\n",
       "   460,\n",
       "   520,\n",
       "   620,\n",
       "   700,\n",
       "   720,\n",
       "   780,\n",
       "   980,\n",
       "   1020,\n",
       "   1160,\n",
       "   1300,\n",
       "   1360,\n",
       "   1440,\n",
       "   1760,\n",
       "   1920,\n",
       "   1960,\n",
       "   2000,\n",
       "   2040,\n",
       "   2080,\n",
       "   2120,\n",
       "   2140,\n",
       "   2160,\n",
       "   2220,\n",
       "   2360,\n",
       "   2420,\n",
       "   2500,\n",
       "   3360,\n",
       "   3600,\n",
       "   3660,\n",
       "   3740,\n",
       "   5580,\n",
       "   5700,\n",
       "   5740,\n",
       "   5820,\n",
       "   5940,\n",
       "   6000,\n",
       "   6040,\n",
       "   8380,\n",
       "   8460,\n",
       "   8580,\n",
       "   8660,\n",
       "   10620,\n",
       "   10720,\n",
       "   10820,\n",
       "   10880,\n",
       "   10920,\n",
       "   10980,\n",
       "   11020,\n",
       "   11140,\n",
       "   11160,\n",
       "   12620,\n",
       "   12820,\n",
       "   12980,\n",
       "   13160,\n",
       "   13280,\n",
       "   15500,\n",
       "   15600,\n",
       "   15660,\n",
       "   15740,\n",
       "   15840,\n",
       "   15900,\n",
       "   15940,\n",
       "   16040,\n",
       "   17500,\n",
       "   17580,\n",
       "   17660,\n",
       "   17760,\n",
       "   18460,\n",
       "   18560,\n",
       "   18600,\n",
       "   18640,\n",
       "   18700],\n",
       "  'probabilities': [0.9999734163284302,\n",
       "   0.999976396560669,\n",
       "   0.9999445676803589,\n",
       "   0.9843423962593079,\n",
       "   0.9999665021896362,\n",
       "   0.999981164932251,\n",
       "   0.9750428795814514,\n",
       "   0.9977033734321594,\n",
       "   0.999941349029541,\n",
       "   0.9998986721038818,\n",
       "   0.9999539852142334,\n",
       "   0.9998244643211365,\n",
       "   0.9992128610610962,\n",
       "   0.9998588562011719,\n",
       "   0.9999504089355469,\n",
       "   0.9999581575393677,\n",
       "   0.9976007342338562,\n",
       "   0.9975600242614746,\n",
       "   0.9934039115905762,\n",
       "   0.9999790191650391,\n",
       "   0.9999884366989136,\n",
       "   0.9999854564666748,\n",
       "   0.999988317489624,\n",
       "   0.9997223019599915,\n",
       "   0.9999899864196777,\n",
       "   0.9999287128448486,\n",
       "   0.9999115467071533,\n",
       "   0.5853059887886047,\n",
       "   0.9999754428863525,\n",
       "   0.9999843835830688,\n",
       "   0.9999650716781616,\n",
       "   0.9385724067687988,\n",
       "   0.999815046787262,\n",
       "   0.9997138381004333,\n",
       "   0.9999487400054932,\n",
       "   0.7080228328704834,\n",
       "   0.9997372031211853,\n",
       "   0.9997536540031433,\n",
       "   0.9997676014900208,\n",
       "   0.9833457469940186,\n",
       "   0.999062716960907,\n",
       "   0.9990033507347107,\n",
       "   0.9944372177124023,\n",
       "   0.9949944019317627,\n",
       "   0.5872707962989807,\n",
       "   0.994159460067749,\n",
       "   0.9482923150062561,\n",
       "   0.9993195533752441,\n",
       "   0.9995090961456299,\n",
       "   0.9989656209945679,\n",
       "   0.9997770190238953,\n",
       "   0.9992843270301819,\n",
       "   0.9984277486801147,\n",
       "   0.9993808269500732,\n",
       "   0.9954948425292969,\n",
       "   0.9968485236167908,\n",
       "   0.9926645159721375,\n",
       "   0.9998927116394043,\n",
       "   0.9987806677818298,\n",
       "   0.9949272871017456,\n",
       "   0.8625390529632568,\n",
       "   0.999594509601593,\n",
       "   0.9993225336074829,\n",
       "   0.9992098808288574,\n",
       "   0.9467375874519348,\n",
       "   0.9988164901733398,\n",
       "   0.9879321455955505,\n",
       "   0.990170419216156,\n",
       "   0.873579204082489,\n",
       "   0.9996157884597778,\n",
       "   0.9969456791877747,\n",
       "   0.9997046589851379,\n",
       "   0.9986088275909424,\n",
       "   0.6074267029762268,\n",
       "   0.7860656380653381,\n",
       "   0.6715349555015564,\n",
       "   0.9989429116249084,\n",
       "   0.9363296031951904]}]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.transcribe(['./audio.mp3'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'neutral', 'score': 0.5360649228096008},\n",
       " {'label': 'curiosity', 'score': 0.533858597278595},\n",
       " {'label': 'confusion', 'score': 0.11207719892263412},\n",
       " {'label': 'approval', 'score': 0.007710011675953865},\n",
       " {'label': 'annoyance', 'score': 0.005330291111022234},\n",
       " {'label': 'surprise', 'score': 0.0037367604672908783},\n",
       " {'label': 'realization', 'score': 0.0033943159505724907},\n",
       " {'label': 'optimism', 'score': 0.0029098447412252426},\n",
       " {'label': 'desire', 'score': 0.0025001955218613148},\n",
       " {'label': 'excitement', 'score': 0.002343252766877413},\n",
       " {'label': 'disapproval', 'score': 0.002214104635640979},\n",
       " {'label': 'amusement', 'score': 0.002040176885202527},\n",
       " {'label': 'love', 'score': 0.0020073307678103447},\n",
       " {'label': 'admiration', 'score': 0.0016995157347992063},\n",
       " {'label': 'caring', 'score': 0.0015249243006110191},\n",
       " {'label': 'anger', 'score': 0.0015176724409684539},\n",
       " {'label': 'disappointment', 'score': 0.0014531872002407908},\n",
       " {'label': 'sadness', 'score': 0.0010677888058125973},\n",
       " {'label': 'joy', 'score': 0.0010504074161872268},\n",
       " {'label': 'disgust', 'score': 0.0007407564553432167},\n",
       " {'label': 'gratitude', 'score': 0.0007391948602162302},\n",
       " {'label': 'fear', 'score': 0.0006978394812904298},\n",
       " {'label': 'embarrassment', 'score': 0.00047342071775346994},\n",
       " {'label': 'remorse', 'score': 0.00044547737343236804},\n",
       " {'label': 'nervousness', 'score': 0.00037569025880657136},\n",
       " {'label': 'grief', 'score': 0.0002608471259009093},\n",
       " {'label': 'relief', 'score': 0.00015891174552962184},\n",
       " {'label': 'pride', 'score': 5.343957673176192e-05}]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier([text])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/20/2023 15:32:49 - INFO - huggingsound.speech_recognition.model - Loading model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "config.json: 100%|██████████| 2.28k/2.28k [00:00<00:00, 2.29MB/s]\n",
      "d:\\WorkSpace\\Projects\\Sentify\\venv\\lib\\site-packages\\transformers\\configuration_utils.py:387: UserWarning: Passing `gradient_checkpointing` to a config initialization is deprecated and will be removed in v5 Transformers. Using `model.gradient_checkpointing_enable()` instead, or if you are using the `Trainer` API, pass `gradient_checkpointing=True` in your `TrainingArguments`.\n",
      "  warnings.warn(\n",
      "pytorch_model.bin: 100%|██████████| 1.27G/1.27G [00:19<00:00, 65.5MB/s]\n",
      "Some weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at ehcalabres/wav2vec2-lg-xlsr-en-speech-emotion-recognition and are newly initialized: ['lm_head.weight', 'lm_head.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "preprocessor_config.json: 100%|██████████| 214/214 [00:00<?, ?B/s] \n",
      "d:\\WorkSpace\\Projects\\Sentify\\venv\\lib\\site-packages\\transformers\\models\\wav2vec2\\processing_wav2vec2.py:54: FutureWarning: Loading a tokenizer inside Wav2Vec2Processor from a config that does not include a `tokenizer_class` attribute is deprecated and will be removed in v5. Please add `'tokenizer_class': 'Wav2Vec2CTCTokenizer'` attribute to either your `config.json` or `tokenizer_config.json` file to suppress this warning: \n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/20/2023 15:33:19 - WARNING - huggingsound.speech_recognition.model - Not fine-tuned model! You'll need to fine-tune it before use this model for audio transcription\n"
     ]
    }
   ],
   "source": [
    "from huggingsound import SpeechRecognitionModel\n",
    "\n",
    "model = SpeechRecognitionModel(\"ehcalabres/wav2vec2-lg-xlsr-en-speech-emotion-recognition\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Not fine-tuned model! Please, fine-tune the model first.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtranscribe\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43martifacts/Audio/main.wav\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\WorkSpace\\Projects\\Sentify\\venv\\lib\\site-packages\\huggingsound\\speech_recognition\\model.py:109\u001b[0m, in \u001b[0;36mSpeechRecognitionModel.transcribe\u001b[1;34m(self, paths, batch_size, decoder)\u001b[0m\n\u001b[0;32m     81\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\" \u001b[39;00m\n\u001b[0;32m     82\u001b[0m \u001b[38;5;124;03mTranscribe audio files.\u001b[39;00m\n\u001b[0;32m     83\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    105\u001b[0m \u001b[38;5;124;03m        }, ...]\u001b[39;00m\n\u001b[0;32m    106\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_finetuned:\n\u001b[1;32m--> 109\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNot fine-tuned model! Please, fine-tune the model first.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m decoder \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    112\u001b[0m     decoder \u001b[38;5;241m=\u001b[39m GreedyDecoder(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtoken_set)\n",
      "\u001b[1;31mValueError\u001b[0m: Not fine-tuned model! Please, fine-tune the model first."
     ]
    }
   ],
   "source": [
    "model.transcribe(['artifacts/Audio/main.wav'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at xbgoose/hubert-speech-emotion-recognition-russian-dusha-finetuned were not used when initializing HubertForSequenceClassification: ['hubert.encoder.pos_conv_embed.conv.weight_g', 'hubert.encoder.pos_conv_embed.conv.weight_v']\n",
      "- This IS expected if you are initializing HubertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing HubertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of HubertForSequenceClassification were not initialized from the model checkpoint at xbgoose/hubert-speech-emotion-recognition-russian-dusha-finetuned and are newly initialized: ['hubert.encoder.pos_conv_embed.conv.parametrizations.weight.original1', 'hubert.encoder.pos_conv_embed.conv.parametrizations.weight.original0']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From d:\\WorkSpace\\Projects\\Sentify\\venv\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "positive\n"
     ]
    }
   ],
   "source": [
    "from transformers import HubertForSequenceClassification, Wav2Vec2FeatureExtractor\n",
    "import torchaudio\n",
    "import torch\n",
    "\n",
    "feature_extractor = Wav2Vec2FeatureExtractor.from_pretrained(\"facebook/hubert-large-ls960-ft\")\n",
    "model = HubertForSequenceClassification.from_pretrained(\"xbgoose/hubert-speech-emotion-recognition-russian-dusha-finetuned\")\n",
    "num2emotion = {0: 'neutral', 1: 'angry', 2: 'positive', 3: 'sad', 4: 'other'}\n",
    "\n",
    "filepath = \"artifacts/Audio/main.wav\"\n",
    "\n",
    "waveform, sample_rate = torchaudio.load(filepath, normalize=True)\n",
    "transform = torchaudio.transforms.Resample(sample_rate, 16000)\n",
    "waveform = transform(waveform)\n",
    "\n",
    "inputs = feature_extractor(\n",
    "        waveform, \n",
    "        sampling_rate=feature_extractor.sampling_rate, \n",
    "        return_tensors=\"pt\",\n",
    "        padding=True,\n",
    "        max_length=16000 * 10,\n",
    "        truncation=True\n",
    "    )\n",
    "\n",
    "logits = model(inputs['input_values'][0]).logits\n",
    "predictions = torch.argmax(logits, dim=-1)\n",
    "predicted_emotion = num2emotion[predictions.numpy()[0]]\n",
    "print(predicted_emotion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
